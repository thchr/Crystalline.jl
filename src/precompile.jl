# Generated by SnoopCompile using
#   tinf = @snoopi_deep begin
#               using Crystalline
#               D = 3
#               for D in 3:-1:2
#                   spacegroup(MAX_SGNUM[D], Val(D))
#                   lgirreps(MAX_SGNUM[D], Val(D))
#                   directbasis(MAX_SGNUM[D], Val(D))
#                   wyckoffs(MAX_SGNUM[D], Val(D))
#                   pointgroup(PG_IUCs[D][end], Val(D))
#                   bandreps(MAX_SGNUM[D], D)
#                   characters(lgirreps(MAX_SGNUM[D], Val(D))["Γ"])
#                   MultTable(primitivize(littlegroups(MAX_SGNUM[D], Val(D))["Γ"]))
#                   conventionalize(primitivize(spacegroup(MAX_SGNUM[D], Val(D)))[end], centering(MAX_SGNUM[D], D))
#               end
#               KVec("0,0,1/2"); KVec("0,1/2")
#               seitz(SymOperation("-x,-y,-z+1")); seitz(SymOperation("-x,-y+1/2"))
#           end
#   julia> ttot, pcs = SnoopCompile.parcel(tinf; tmin=0.05)
#   julia> SnoopCompile.write("src/precompile.jl", pcs[end][end][end])
#
# I then manually removed several of the methods that "ping" the on disk (e.g., 
# `spacegroup`, `lgirreps`, `bandreps`, `littlegroups`) since they seem to
# invalidate themselves on package load (they all depend on some global state via the
# currently non-relocatable files they load data from; maybe they need to be Artifacts to 
# not do that?). In addition, I manually removed several other precompile statements that
# ultimately seemed to cause _increased_ latency (again, perhaps due to invalidation).
# What remains is rather modest, but I think a net, albeit modest, win.

function _precompile_()
    ccall(:jl_generating_output, Cint, ()) == 1 || return nothing    
    
    Base.precompile(Tuple{typeof(seitz),SymOperation{3}})   # time: 0.9289543
    Base.precompile(Tuple{typeof(characters),Vector{LGIrrep{3}}})   # time: 0.5580262
    Base.precompile(Tuple{typeof(characters),Vector{LGIrrep{2}}})   # time: 0.1106631
    Base.precompile(Tuple{Type{SymOperation},String})   # time: 0.1149793
end